{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1VDrlsykv-H"
   },
   "source": [
    "# Iris data set: inference with NN / SVI solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFtJgTgGGhKl"
   },
   "source": [
    "Import the required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q4XNbXIfEF86"
   },
   "outputs": [],
   "source": [
    "import pyro\n",
    "import numpy\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import model_selection\n",
    "from pyro.infer.mcmc import NUTS, MCMC\n",
    "import pyro.distributions as pdist\n",
    "import torch.distributions as tdist\n",
    "import torch.nn as tnn\n",
    "import pyro.nn as pnn\n",
    "import arviz as az\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq-JwynsGnQM"
   },
   "source": [
    "Set some parameters for inference and make reproducible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2UJmvt3aEKHc"
   },
   "outputs": [],
   "source": [
    "seed_value = 42  # Replace with your desired seed value\n",
    "torch.manual_seed(seed_value)\n",
    "pyro.set_rng_seed(seed_value)\n",
    "numpy.random.seed(seed_value)\n",
    "\n",
    "# MAP or diagonal normal?\n",
    "MAP=True\n",
    "if MAP:\n",
    "  MAXIT=2000 # SVI iterations\n",
    "  REPORT=200 # Plot ELBO each time after this amount of SVI iterations\n",
    "else:\n",
    "  MAXIT=100000\n",
    "  REPORT=1000\n",
    "\n",
    "# Number of samples used in prediction\n",
    "S=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c5o-ZELGsl3"
   },
   "source": [
    "Function to evaluate the accuracy of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vqYEZfKRENmM"
   },
   "outputs": [],
   "source": [
    "def accuracy(pred, data):\n",
    "  \"\"\"\n",
    "  Calculate accuracy of predicted labels (integers).\n",
    "\n",
    "  pred: predictions, tensor[sample_index, chain_index, data_index, logits]\n",
    "  data: actual data (digit), tensor[data_index]\n",
    "\n",
    "  Prediction is taken as most common predicted value.\n",
    "  Returns accuracy (#correct/#total).\n",
    "  \"\"\"\n",
    "  n=data.shape[0]\n",
    "  correct=0\n",
    "  total=0\n",
    "  for i in range(0, n):\n",
    "      # Get most common prediction value from logits\n",
    "      pred_i=int(torch.argmax(torch.sum(pred[:,0,i,:],0)))\n",
    "      # Compare prediction with data\n",
    "      if int(data[i])==int(pred_i):\n",
    "          correct+=1.0\n",
    "      total+=1.0\n",
    "  # Return fractional accuracy\n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcC99pQAGQz1"
   },
   "source": [
    "Load the [iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) set from [scikit-learn](https://sklearn.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jlftJLaLEOXc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set / test set sizes: 100, 50.\n"
     ]
    }
   ],
   "source": [
    "# Iris data set\n",
    "Dx=4 # Input vector dim\n",
    "Dy=3 # Number of labels\n",
    "\n",
    "iris=sklearn.datasets.load_iris()\n",
    "x_all=torch.tensor(iris.data, dtype=torch.float) # Input vector (4D)\n",
    "y_all=torch.tensor(iris.target, dtype=torch.int) # Label(3 classes)\n",
    "\n",
    "# Make training and test set\n",
    "x, x_test, y, y_test = sklearn.model_selection.train_test_split(\n",
    "    x_all, y_all, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Data set / test set sizes: %i, %i.\" % (x.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCnoKMBxG9sH"
   },
   "source": [
    "The probabilistic model, implemented as a callable class. We could also simply use a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MQ0QoZ44xpVt"
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, x_dim=4, y_dim=3, h_dim=5):\n",
    "        self.x_dim=x_dim\n",
    "        self.y_dim=y_dim\n",
    "        self.h_dim=h_dim\n",
    "\n",
    "    def __call__(self, x, y=None):\n",
    "        \"\"\"\n",
    "        We need None for predictive\n",
    "        \"\"\"\n",
    "        x_dim=self.x_dim\n",
    "        y_dim=self.y_dim\n",
    "        h_dim=self.h_dim\n",
    "        # Number of observations\n",
    "        n=x.shape[0]\n",
    "        # standard deviation of Normals\n",
    "        sd=1 # EXERCISE: 100->1\n",
    "        # Layer 1\n",
    "        w1=pyro.sample(\"w1\", pdist.Normal(0, sd).expand([x_dim, h_dim]).to_event(2))\n",
    "        b1=pyro.sample(\"b1\", pdist.Normal(0, sd).expand([h_dim]).to_event(1))\n",
    "        # Layer 2 # EXERCISE: added layer\n",
    "        w2=pyro.sample(\"w2\", pdist.Normal(0, sd).expand([h_dim, h_dim]).to_event(2))\n",
    "        b2=pyro.sample(\"b2\", pdist.Normal(0, sd).expand([h_dim]).to_event(1))\n",
    "        # Layer 3\n",
    "        w3=pyro.sample(\"w3\", pdist.Normal(0, sd).expand([h_dim, y_dim]).to_event(2))\n",
    "        b3=pyro.sample(\"b3\", pdist.Normal(0, sd).expand([y_dim]).to_event(1))\n",
    "        # NN\n",
    "        h1=torch.tanh((x @ w1) + b1)\n",
    "        h2=torch.tanh((h1 @ w2) + b2) # EXERCISE: added layer\n",
    "        logits=(h2 @ w3 + b3)\n",
    "        # Save deterministc variable (logits) in trace\n",
    "        pyro.deterministic(\"logits\", logits)\n",
    "        # Categorical likelihood\n",
    "        with pyro.plate(\"labels\", n):\n",
    "            obs=pyro.sample(\"obs\", pdist.Categorical(logits=logits), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzZv1cqr5jPc"
   },
   "source": [
    "# NUTS inferece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fkX2bz3Q5irs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|████████████████████████████| 150/150 [02:50,  1.13s/it, step size=1.20e-02, acc. prob=0.846]\n"
     ]
    }
   ],
   "source": [
    "# Perform inference using NUTS\n",
    "# Instantiate the Model object\n",
    "model=Model()\n",
    "\n",
    "# NUTS\n",
    "nuts_kernel = NUTS(model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=50)\n",
    "mcmc.run(x, y)\n",
    "\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WO7JKDEc-tPZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 100), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS Summary (R-hat and ESS):\n",
      "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "w1[0, 0]  0.074  0.899  -1.563    2.049      0.161    0.115      35.0   \n",
      "w1[0, 1] -0.301  0.793  -1.684    1.149      0.147    0.105      29.0   \n",
      "w1[0, 2]  0.185  0.678  -1.068    1.263      0.373    0.291       4.0   \n",
      "w1[0, 3] -0.112  1.001  -1.796    1.908      0.163    0.128      37.0   \n",
      "w1[0, 4]  0.238  0.763  -1.337    1.323      0.159    0.114      25.0   \n",
      "...         ...    ...     ...      ...        ...      ...       ...   \n",
      "w3[4, 1] -0.339  1.319  -2.407    2.101      0.179    0.127      54.0   \n",
      "w3[4, 2] -0.259  1.401  -3.080    2.007      0.307    0.220      21.0   \n",
      "b3[0]     0.036  0.762  -1.206    1.438      0.086    0.071      84.0   \n",
      "b3[1]    -0.210  0.908  -2.219    1.062      0.114    0.081      63.0   \n",
      "b3[2]    -0.008  0.914  -1.650    1.663      0.134    0.095      47.0   \n",
      "\n",
      "          ess_tail  r_hat  \n",
      "w1[0, 0]      61.0    NaN  \n",
      "w1[0, 1]      31.0    NaN  \n",
      "w1[0, 2]      86.0    NaN  \n",
      "w1[0, 3]      42.0    NaN  \n",
      "w1[0, 4]      75.0    NaN  \n",
      "...            ...    ...  \n",
      "w3[4, 1]      78.0    NaN  \n",
      "w3[4, 2]      49.0    NaN  \n",
      "b3[0]         75.0    NaN  \n",
      "b3[1]         75.0    NaN  \n",
      "b3[2]         76.0    NaN  \n",
      "\n",
      "[73 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics from Arviz\n",
    "nuts_inference = az.from_pyro(mcmc)\n",
    "nuts_summary = az.summary(nuts_inference, var_names=[\"w1\", \"b1\", \"w2\", \"b2\", \"w3\", \"b3\"])\n",
    "\n",
    "# Print the summary\n",
    "print(\"NUTS Summary (R-hat and ESS):\")\n",
    "print(nuts_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kmcd75ehBnpK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of posterior preditive for y (logits): torch.Size([100, 1, 50, 3])\n",
      "Success: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Get posterior predictives (logits) from NUTS\n",
    "train_predict = pyro.infer.Predictive(model, posterior_samples)(x_test, None)\n",
    "# Print accuracy\n",
    "logits=train_predict['logits']\n",
    "print(\"Shape of posterior preditive for y (logits):\", logits.shape)\n",
    "print(\"Success: %.2f\" % accuracy(logits, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
